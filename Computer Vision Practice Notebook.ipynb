{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Practice Notebook\n",
    "\n",
    "Working with pretrained networks and the MINST dataset.  Code adapted from Yassine Ghouzam on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 5 layers Sequential Convolutional Neural Network for digits recognition trained on MNIST dataset. I choosed to build it with keras API (Tensorflow backend) which is very intuitive. Firstly, I will prepare the data (handwritten digits images) then I will focus on the CNN modeling and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications import VGG19\n",
    "# cnn_base = VGG19(weights='imagenet',\n",
    "#                   include_top=False,\n",
    "#                   input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(x.isna().any().sum())\n",
    "print(test_data.isna().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['label']\n",
    "x = train_data.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are distributed evenly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data. Previusly I've used sklearns minmax scaler or standardscaler but in this case I already know the values and will remind me of what I'm doing to do this in with plain math.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x / 255.\n",
    "test_data = test_data / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping images in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "possibbly the hardest part of CV for me is conceptualizing the matrix.  In this case 28*28 = 784 and we have just one channel = greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = x.values.reshape(-1,28,28,1)\n",
    "test_data = test_data.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for 10 different classes\n",
    "y = to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_tr, X_val, Y_tr, Y_val = train_test_split(x, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c1b9af6518>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_tr[7][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c1b9acd048>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_tr[15][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n",
    "\n",
    "The first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 32 filters for the two firsts conv2D layers and 16 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n",
    "\n",
    "The CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n",
    "\n",
    "The second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n",
    "\n",
    "Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n",
    "\n",
    "Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n",
    "\n",
    "'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.\n",
    "\n",
    "The Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n",
    "\n",
    "In the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate = 0.75))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(rate = 0.75))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Set the optimizer and annealer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\".\n",
    "\n",
    "The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n",
    "\n",
    "I choose RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n",
    "\n",
    "The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with a high LR and the optimizer could probably fall into a local minima.\n",
    "\n",
    "Its better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.\n",
    "\n",
    "To keep the advantage of the fast computation time with a high LR, i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).\n",
    "\n",
    "With the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "epochs = 30 # More epochs means more training time and better results although too many can lead to overfitting\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In order to avoid overfitting problem, we need to expand artificially our handwritten digit dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.\n",
    "\n",
    "For example, the number is not centered The scale is not the same (some who write with big/small numbers) The image is rotated...\n",
    "\n",
    "Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n",
    "\n",
    "By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 166s - loss: 0.4510 - acc: 0.8631 - val_loss: 0.1435 - val_acc: 0.9583\n",
      "Epoch 2/30\n",
      " - 206s - loss: 0.3995 - acc: 0.8767 - val_loss: 0.1307 - val_acc: 0.9595\n",
      "Epoch 3/30\n",
      " - 203s - loss: 0.3730 - acc: 0.8883 - val_loss: 0.2066 - val_acc: 0.9412\n",
      "Epoch 4/30\n",
      " - 205s - loss: 0.3453 - acc: 0.8990 - val_loss: 0.1279 - val_acc: 0.9640\n",
      "Epoch 5/30\n",
      " - 205s - loss: 0.3252 - acc: 0.9035 - val_loss: 0.1173 - val_acc: 0.9657\n",
      "Epoch 6/30\n",
      " - 204s - loss: 0.3058 - acc: 0.9078 - val_loss: 0.1563 - val_acc: 0.9564\n",
      "Epoch 7/30\n",
      " - 204s - loss: 0.2951 - acc: 0.9115 - val_loss: 0.2001 - val_acc: 0.9398\n",
      "Epoch 8/30\n",
      " - 203s - loss: 0.2858 - acc: 0.9152 - val_loss: 0.1283 - val_acc: 0.9652\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/30\n",
      " - 208s - loss: 0.2505 - acc: 0.9259 - val_loss: 0.1023 - val_acc: 0.9693\n",
      "Epoch 10/30\n",
      " - 202s - loss: 0.2468 - acc: 0.9292 - val_loss: 0.1219 - val_acc: 0.9640\n",
      "Epoch 11/30\n",
      " - 203s - loss: 0.2421 - acc: 0.9296 - val_loss: 0.1102 - val_acc: 0.9683\n",
      "Epoch 12/30\n",
      " - 203s - loss: 0.2323 - acc: 0.9331 - val_loss: 0.1373 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/30\n",
      " - 202s - loss: 0.2282 - acc: 0.9333 - val_loss: 0.1087 - val_acc: 0.9688\n",
      "Epoch 14/30\n",
      " - 203s - loss: 0.2132 - acc: 0.9380 - val_loss: 0.1085 - val_acc: 0.9688\n",
      "Epoch 15/30\n",
      " - 203s - loss: 0.2203 - acc: 0.9360 - val_loss: 0.1105 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/30\n",
      " - 202s - loss: 0.2060 - acc: 0.9391 - val_loss: 0.0946 - val_acc: 0.9733\n",
      "Epoch 17/30\n",
      " - 203s - loss: 0.2068 - acc: 0.9401 - val_loss: 0.1131 - val_acc: 0.9671\n",
      "Epoch 18/30\n",
      " - 203s - loss: 0.2045 - acc: 0.9417 - val_loss: 0.0898 - val_acc: 0.9738\n",
      "Epoch 19/30\n",
      " - 203s - loss: 0.2058 - acc: 0.9390 - val_loss: 0.1023 - val_acc: 0.9688\n",
      "Epoch 20/30\n",
      " - 203s - loss: 0.2034 - acc: 0.9402 - val_loss: 0.1051 - val_acc: 0.9695\n",
      "Epoch 21/30\n",
      " - 202s - loss: 0.1998 - acc: 0.9418 - val_loss: 0.1072 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 22/30\n",
      " - 204s - loss: 0.1958 - acc: 0.9417 - val_loss: 0.0963 - val_acc: 0.9707\n",
      "Epoch 23/30\n",
      " - 204s - loss: 0.1987 - acc: 0.9409 - val_loss: 0.1088 - val_acc: 0.9650\n",
      "Epoch 24/30\n",
      " - 203s - loss: 0.1968 - acc: 0.9423 - val_loss: 0.1072 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 25/30\n",
      " - 204s - loss: 0.1901 - acc: 0.9442 - val_loss: 0.0943 - val_acc: 0.9714\n",
      "Epoch 26/30\n",
      " - 203s - loss: 0.2021 - acc: 0.9416 - val_loss: 0.0950 - val_acc: 0.9707\n",
      "Epoch 27/30\n",
      " - 205s - loss: 0.1954 - acc: 0.9444 - val_loss: 0.0975 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 28/30\n",
      " - 203s - loss: 0.1965 - acc: 0.9429 - val_loss: 0.0974 - val_acc: 0.9705\n",
      "Epoch 29/30\n",
      " - 203s - loss: 0.1973 - acc: 0.9433 - val_loss: 0.1028 - val_acc: 0.9702\n",
      "Epoch 30/30\n",
      " - 204s - loss: 0.1922 - acc: 0.9441 - val_loss: 0.0996 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Wall time: 1h 41min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_tr,Y_tr, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch= (X_tr.shape[0] // batch_size)\n",
    "                              , callbacks=[learning_rate_reduction]) #entertain the use of early stopping and saving in callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D\t Dense\t Dropout\t Flatten\t Image\t ImageDataGenerator\t MaxPool2D\t RMSprop\t ReduceLROnPlateau\t \n",
      "Sequential\t X_tr\t X_val\t Y_tr\t Y_val\t array_to_img\t ax\t batch_size\t confusion_matrix\t \n",
      "datagen\t epochs\t fig\t g\t itertools\t learning_rate_reduction\t model\t mpimg\t ndimage\t \n",
      "np\t optimizer\t os\t pd\t plt\t scipy\t shutil\t sns\t test_data\t \n",
      "time\t to_categorical\t train_data\t train_test_split\t x\t y\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9b74fd02b364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation loss\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlegend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshadow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting loss and acc curves for training and validation sets\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Conf matrix\n",
    "def plot_conf_matrix(cm, classes, normalize=False, \n",
    "                          title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    Draws a heat map to show true positives, false positives, &c\n",
    "    for given predicted y values vs actual y values.\n",
    "    Parameters:\n",
    "    cm (np.array) The confusion matrix for a model's predictions.\n",
    "    classes (list) Names of classes/categories.\n",
    "    normalize (bool) Whether to normalize the numbers in the matrix.\n",
    "    Returns:\n",
    "    Visualized heat map of the confusion matrix.\n",
    "    '''\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_conf_matrix(confusion_mtx, classes = range(10)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
